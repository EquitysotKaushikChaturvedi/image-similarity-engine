{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "13664290",
            "metadata": {},
            "source": [
                "# Train (Index) on Your Own Data\n",
                "\n",
                "I created this notebook so you can easily create a new search engine model based on **your own images**.\n",
                "\n",
                "### **How it works:**\n",
                "1. You enter the path to your folder of images.\n",
                "2. I wrote a script to scan the folder and \"learn\" (index) every image.\n",
                "3. Then we save the resulting model (index) to a folder of your choice.\n",
                "\n",
                "Let's get started!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "df44c803",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import torch\n",
                "import pickle\n",
                "from PIL import Image\n",
                "from transformers import AutoProcessor, AutoModel\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# I'm forcing usage of GPU if available, otherwise defaulting to CPU.\n",
                "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Running on: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5df3304",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. SETUP MODEL ---\n",
                "# I am using the same powerful model here as in the main project for consistency.\n",
                "MODEL_NAME = \"google/siglip-base-patch16-224\"\n",
                "\n",
                "print(\"Loading AI Model... Please wait...\")\n",
                "processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
                "model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
                "model.eval()\n",
                "print(\"Model Loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "01f791c4",
            "metadata": {},
            "source": [
                "### **Step 2: Enter Your Data Path**\n",
                "Copy and paste the full path to the folder where your images are stored.\n",
                "Example: `C:\\Users\\Name\\Pictures\\MyVacation` or `D:\\Datasets\\Cars`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0bd14966",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_folder = input(\"Enter dataset folder path: \").strip('\"') # I'm removing quotes just in case\n",
                "dataset_path = Path(dataset_folder)\n",
                "\n",
                "if not dataset_path.exists():\n",
                "    print(\"Error: That folder does not exist! Please check the path.\")\n",
                "else:\n",
                "    # I'm scanning for standard image formats here.\n",
                "    valid_exts = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}\n",
                "    image_files = [\n",
                "        p for p in dataset_path.rglob(\"*\") \n",
                "        if p.suffix.lower() in valid_exts\n",
                "    ]\n",
                "    print(f\"Found {len(image_files)} images in '{dataset_path.name}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "04e7db9a",
            "metadata": {},
            "source": [
                "### **Step 3: Train (Index) the Data**\n",
                "This step effectively converts your images into mathematical vectors that the AI understands."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50dc146f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_embedding(path):\n",
                "    try:\n",
                "        image = Image.open(path).convert(\"RGB\")\n",
                "        inputs = processor(images=image, return_tensors=\"pt\").to(DEVICE)\n",
                "        with torch.no_grad():\n",
                "            # Get features - handling both SigLIP and CLIP models\n",
                "            if hasattr(model, 'get_image_features'):\n",
                "                outputs = model.get_image_features(**inputs)\n",
                "            else:\n",
                "                outputs = model.get_text_features(**inputs)\n",
                "            # Normalize the vectors\n",
                "            embedding = outputs / outputs.norm(p=2, dim=-1, keepdim=True)\n",
                "            return embedding.cpu().numpy().flatten()\n",
                "    except Exception as e:\n",
                "        return None\n",
                "\n",
                "embeddings = []\n",
                "filenames = []\n",
                "\n",
                "print(f\"Starting processing of {len(image_files)} images...\")\n",
                "\n",
                "for img_path in tqdm(image_files):\n",
                "    emb = compute_embedding(img_path)\n",
                "    if emb is not None:\n",
                "        embeddings.append(emb)\n",
                "        # I'm saving the path relative to the dataset folder to keep it clean and portable.\n",
                "        filenames.append(str(img_path.relative_to(dataset_path)))\n",
                "\n",
                "print(\"Processing Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "18b6797a",
            "metadata": {},
            "source": [
                "### **Step 4: Save Your New Model**\n",
                "Where should I save this index? You can choose your Downloads folder or the project folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f6fd4cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# I default to a 'custom_model' folder in the current directory, but you can change it.\n",
                "save_dir = input(\"Enter folder path to save model (Press Enter for default 'custom_model'): \").strip()\n",
                "\n",
                "if not save_dir:\n",
                "    save_dir = \"custom_model\"\n",
                "\n",
                "out_path = Path(save_dir)\n",
                "out_path.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "if len(embeddings) > 0:\n",
                "    # Save Embeddings\n",
                "    emb_array = np.vstack(embeddings).astype('float32')\n",
                "    np.save(out_path / \"embeddings.npy\", emb_array)\n",
                "    \n",
                "    # Save Filenames\n",
                "    with open(out_path / \"filenames.pkl\", 'wb') as f:\n",
                "        pickle.dump(filenames, f)\n",
                "        \n",
                "    print(f\"\\nSUCCESS! Model saved to: {out_path.absolute()}\")\n",
                "    print(\"\\nFILES CREATED:\")\n",
                "    print(f\"1. {out_path / 'embeddings.npy'}\")\n",
                "    print(f\"2. {out_path / 'filenames.pkl'}\")\n",
                "    \n",
                "    print(\"\\nTo use this model, point your scripts or API to this folder!\")\n",
                "else:\n",
                "    print(\"Warning: No embeddings were generated. Check your images.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
